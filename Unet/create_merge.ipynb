{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import config\n",
    "\n",
    "from model_structure_3d_2 import UNet3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PyTorch model\n",
    "model = UNet3D()\n",
    "model.load_state_dict(torch.load(\"./saved_models/model_for_vasc_3d2839818.pth\", map_location=\"cpu\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Directory paths for input and output data\n",
    "input_dir = \"./preparations/data/indata\"\n",
    "output_dir = \"./preparations/data/outdata\"\n",
    "\n",
    "# Get a list of image files in the input directory\n",
    "image_files = os.listdir(input_dir)\n",
    "\n",
    "def get_prediction(img, margin):\n",
    "    if margin != 0:\n",
    "        raise ValueError\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.from_numpy(img / 255).unsqueeze(0).float()\n",
    "        output = model(input_tensor)\n",
    "    output_np = output.numpy()\n",
    "    return output_np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 21/21 [01:16<00:00,  3.63s/it]\n",
      "Processing: 100%|██████████| 21/21 [01:14<00:00,  3.55s/it]\n",
      "Processing: 100%|██████████| 21/21 [01:16<00:00,  3.67s/it]\n",
      "Processing: 100%|██████████| 21/21 [01:12<00:00,  3.44s/it]\n",
      "Processing: 100%|██████████| 21/21 [01:11<00:00,  3.42s/it]\n",
      "Processing: 100%|██████████| 21/21 [01:17<00:00,  3.69s/it]\n",
      "Processing: 100%|██████████| 21/21 [01:15<00:00,  3.59s/it]\n",
      "Processing: 100%|██████████| 21/21 [01:16<00:00,  3.63s/it]\n",
      "Processing: 100%|██████████| 21/21 [01:15<00:00,  3.58s/it]\n",
      "Processing: 100%|██████████| 21/21 [01:18<00:00,  3.76s/it]\n"
     ]
    }
   ],
   "source": [
    "trueColor = (0, 255, 0)\n",
    "falseColor = (0, 0, 255)\n",
    "\n",
    "image_stacks = 10\n",
    "\n",
    "path_in = \"./preparations/data/indata\"\n",
    "path_out = \"./preparations/data/outdata\"\n",
    "\n",
    "paths_in = os.listdir(path_in)\n",
    "paths_out = os.listdir(path_out)\n",
    "\n",
    "first_image_index = 100\n",
    "index = first_image_index\n",
    "\n",
    "for k in range(first_image_index, first_image_index + image_stacks * config.NUM_PICS, config.NUM_PICS):\n",
    "    images_in = []\n",
    "    images_out = []\n",
    "    for i in range(config.NUM_PICS):\n",
    "        img_in = cv2.imread(os.path.join(path_in, paths_in[k + i]), cv2.IMREAD_GRAYSCALE)\n",
    "        img_out = cv2.imread(os.path.join(path_out, paths_out[k + i]), cv2.IMREAD_GRAYSCALE)\n",
    "        images_in.append(img_in)\n",
    "        images_out.append(img_out)\n",
    "    images_in = np.array([images_in])\n",
    "    images_out = np.array([images_out])\n",
    "\n",
    "    step = 64\n",
    "    shape = images_in.shape\n",
    "    count_times = np.zeros(shape)\n",
    "    total_times = np.zeros(shape)\n",
    "\n",
    "    for i in tqdm(range(0, shape[2] - shape[2] % step, step), desc=\"Processing\"):\n",
    "        for j in range(0, shape[3] - shape[3] % step, step):\n",
    "            slice_tmp = images_in[:, :,i : i + config.HEIGHT, j : j + config.WIDTH]\n",
    "            array_tmp = get_prediction(slice_tmp, 0)[0]\n",
    "            count_times[:, :, i : (i + config.HEIGHT), j : (j + config.WIDTH)] += (array_tmp > 0.5)\n",
    "            total_times[:, :, i : (i + config.HEIGHT), j : (j + config.WIDTH)] += 1\n",
    "    confidence = (count_times + 0.0001) / (total_times + 0.0001)\n",
    "    images_predict = (np.floor(confidence * 255)).astype(np.uint8)[0]\n",
    "    \n",
    "    # Initialize img_blend with img_in\n",
    "    img_blend = np.zeros(images_in.shape + (3,), dtype=np.uint8)\n",
    "\n",
    "    # Apply blending rules\n",
    "    # Rule 1: Where img_out and img_predict are both 0, put the color that was in img_in\n",
    "    img_blend[(images_out == 0) & (images_predict == 0)] = np.stack([images_in] * 3, axis=-1)[(images_out == 0) & (images_predict == 0)]\n",
    "\n",
    "    # Rule 2: Where img_out and img_predict are both 255, multiply trueColor with the number in img_in and put it back\n",
    "    img_blend[(images_out == 255) & (images_predict == 255)] = np.array(trueColor) * np.stack([images_in] * 3, axis=-1)[(images_out == 255) & (images_predict == 255)] / 255\n",
    "\n",
    "    # Rule 3: Where img_out and img_predict are different, multiply by falseColor and put it back\n",
    "    img_blend[(images_out != images_predict)] = np.array(falseColor) * np.stack([images_in] * 3, axis=-1)[(images_out != images_predict)] / 255\n",
    "\n",
    "    for x in img_blend[0]:\n",
    "        cv2.imwrite(os.path.join(\"./blend_images\", str(1000000 + index) + \".png\"), x)\n",
    "        index += 1\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 16, 1356, 1356, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img_blend.shape)\n",
    "cv2.imshow(\"img_blend\", img_blend[0][0])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_combined_image(img_in, img_out):\n",
    "    n = img_in.shape[0]\n",
    "    combined_img = np.zeros((n, n, 3), dtype=np.uint8)\n",
    "    true_color = np.array([0, 255, 0], dtype=np.uint8)\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if img_out[i, j] == 255:\n",
    "                combined_img[i, j] = img_in[i, j] * true_color\n",
    "            else:\n",
    "                combined_img[i, j] = img_in[i, j]\n",
    "\n",
    "    return combined_img\n",
    "\n",
    "trueColor = (0, 255, 0)\n",
    "falseColor = (0, 0, 255)\n",
    "\n",
    "image_stacks = 10\n",
    "\n",
    "path_in = \"./preparations/data/indata\"\n",
    "path_out = \"./preparations/data/outdata\"\n",
    "\n",
    "paths_in = os.listdir(path_in)\n",
    "paths_out = os.listdir(path_out)\n",
    "\n",
    "first_image_index = 100\n",
    "index = first_image_index\n",
    "\n",
    "for k in range(first_image_index, first_image_index + image_stacks * config.NUM_PICS):\n",
    "    img_in = cv2.imread(os.path.join(path_in, paths_in[k]), cv2.IMREAD_GRAYSCALE)\n",
    "    img_out = cv2.imread(os.path.join(path_out, paths_out[k]), cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
