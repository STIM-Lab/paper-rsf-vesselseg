{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial shape: (1, 200, 200, 200)\n",
      "64 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 13/13 [00:50<00:00,  3.85s/it]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import config\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "from model_structures.models_together import UNet3D\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy as copy\n",
    "\n",
    "# Load the PyTorch model\n",
    "path_model = \"./saved_models/LSM/model_for_vasc_3d_2l_2464848.pth\"\n",
    "name = path_model.split(\"/\")[-2]\n",
    "model = UNet3D(number_of_layers=2)\n",
    "model.load_state_dict(torch.load(path_model, map_location=\"cpu\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Directory paths for input and output data\n",
    "# input_dir = \"./preparations/data/indata\"\n",
    "# output_dir = \"./preparations/data/outdata\"\n",
    "\n",
    "# Get a list of image files in the input directory\n",
    "# image_files = os.listdir(input_dir)\n",
    "\n",
    "def get_prediction(img, margin):\n",
    "    if margin != 0:\n",
    "        raise ValueError\n",
    "    with torch.no_grad():\n",
    "        input_tensor = torch.from_numpy(img).unsqueeze(0).float()\n",
    "        output = model(input_tensor)\n",
    "    output_np = output.numpy()\n",
    "    return output_np\n",
    "\n",
    "def calculate_binary_array(count_array, total_array):\n",
    "    # Avoid division by zero by setting a mask for total_array equal to zero\n",
    "    mask = total_array == 0\n",
    "    \n",
    "    # Initialize binary_array with all zeros\n",
    "    new_array = np.zeros_like(count_array)\n",
    "    \n",
    "    # Calculate binary_array where total_array is not zero\n",
    "    new_array[~mask] = (count_array[~mask] / total_array[~mask]) >= 0.5\n",
    "    \n",
    "    return new_array\n",
    "\n",
    "def calculate_slices(i, j, k, shape):\n",
    "    slices = (\n",
    "        slice(None),\n",
    "        slice(min(i * config.NUM_PICS, shape[1] - config.NUM_PICS), min((i + 1) * config.NUM_PICS, shape[1])),\n",
    "        slice(min(j * step, shape[2] - config.HEIGHT), min(j * step + config.HEIGHT, shape[2])),\n",
    "        slice(min(k * step, shape[3] - config.WIDTH), min(k * step + config.WIDTH, shape[3]))\n",
    "    )\n",
    "    return slices\n",
    "\n",
    "arg = -1\n",
    "# Create a nrrd file from a prediction based on the input directory\n",
    "image_array = np.load(\"./unprocessed_data/LSM/volume_input.npy\")\n",
    "if arg > 0:\n",
    "    if arg == 1:\n",
    "        blur_array = [cv2.GaussianBlur(image_array[i], (5, 5), 0) for i in range(image_array.shape[0])]\n",
    "        image_init = np.expand_dims(blur_array, axis=0)\n",
    "    else:\n",
    "        # Apply Pseudo flat field correction\n",
    "        blur_array = [cv2.GaussianBlur(image_array[i], (127, 127), 0) for i in range(image_array.shape[0])]\n",
    "\n",
    "        image_pff_array = [cv2.divide(image_array[i], blur_array[i], scale=255) for i in range(image_array.shape[0])]\n",
    "\n",
    "        # normalize\n",
    "        image_pff_array = (image_pff_array - np.min(image_pff_array)) / (np.max(image_pff_array) - np.min(image_pff_array))\n",
    "\n",
    "        image_init = np.expand_dims(image_pff_array, axis=0)\n",
    "else:\n",
    "    image_init = np.expand_dims(image_array, axis=0)\n",
    "# normalize\n",
    "image_init = (image_init - np.min(image_init)) / (np.max(image_init) - np.min(image_init))\n",
    "\n",
    "# Print the shape of the input and output arrays\n",
    "shape = image_init.shape\n",
    "print(\"Initial shape:\", shape)\n",
    "\n",
    "# Parameters\n",
    "step_ratio = 1\n",
    "step = int(config.HEIGHT / step_ratio)\n",
    "size = config.HEIGHT\n",
    "print(step, size)\n",
    "margin = 0\n",
    "\n",
    "# Create 0 copies of inputs\n",
    "count_array = np.zeros_like(image_init)\n",
    "total_array = np.zeros_like(image_init)\n",
    "\n",
    "index = 0\n",
    "if not os.path.exists(\"./nrrd\"):\n",
    "    os.makedirs(\"./nrrd\")\n",
    "\n",
    "# amount\n",
    "i_amount = np.ceil(shape[1] / config.NUM_PICS)\n",
    "j_amount = np.ceil(shape[2] / step)\n",
    "k_amount = np.ceil(shape[3] / step)\n",
    "\n",
    "for i in tqdm(range(0, int(i_amount)), \"Processing\"):\n",
    "    for j in range(0, int(j_amount)):\n",
    "        for k in range(0, int(k_amount)):\n",
    "            # a b c based on i j k\n",
    "            slices = calculate_slices(i, j, k, shape)\n",
    "            slice_tmp = image_init[slices]\n",
    "            array_tmp = get_prediction(slice_tmp, margin)[0]\n",
    "            count_array[slices] = count_array[slices] + array_tmp\n",
    "            total_array[slices] += 1\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Calculate the binary array\n",
    "binary_array = calculate_binary_array(count_array, total_array)[0]\n",
    "\n",
    "# Save the binary array as a .npy file\n",
    "if not os.path.exists(\"./processed_npy\"):\n",
    "    os.makedirs(\"./processed_npy\")\n",
    "\n",
    "np.save(f\"./processed_npy/{name}.npy\", binary_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "labels = np.load(\"./unprocessed_data/LSM/volume_ground_truth.npy\")\n",
    "result_array = np.zeros(binary_array.shape + (3,), dtype=np.uint8)\n",
    "result_array[(labels == 1) & (binary_array == 1)] = (255, 255, 255)\n",
    "result_array[(labels == 0) & (binary_array == 0)] = (0, 0, 0)\n",
    "result_array[(labels == 1) & (binary_array == 0)] = (255, 0, 0)\n",
    "result_array[(labels == 0) & (binary_array == 1)] = (0, 255, 0)\n",
    "for i in range(binary_array.shape[0]):\n",
    "    cv2.imshow(\"img\", cv2.resize(image_array[i], (512, 512)))\n",
    "    cv2.imshow(\"pred\", cv2.resize(binary_array[i] * 255, (512, 512)))\n",
    "    cv2.imshow(\"result\", cv2.resize(result_array[i], (512, 512)))\n",
    "    cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save bnary_array as nnrd\n",
    "import nrrd\n",
    "name = path_model.split(\"/\")[-2]\n",
    "# create a folder\n",
    "if not os.path.exists(f\"./nrrd/{name}\"):\n",
    "    os.makedirs(f\"./nrrd/{name}\")\n",
    "\n",
    "nrrd.write(f\"./nrrd/{name}/pred_orig.nrrd\", binary_array)\n",
    "\n",
    "flipped = np.flip(np.moveaxis(np.flip(binary_array, axis=2), [0, -2], [2, 1]), axis=0)\n",
    "nrrd.write(f\"./nrrd/{name}/pred_flipped.nrrd\", flipped)\n",
    "\n",
    "# original data\n",
    "nrrd.write(f\"./nrrd/{name}/images_orig.nrrd\", image_array)\n",
    "\n",
    "flipped = np.flip(np.moveaxis(np.flip(image_array, axis=2), [0, -2], [2, 1]), axis=0)\n",
    "nrrd.write(f\"./nrrd/{name}/images_flipped.nrrd\", flipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 2 nrrd files and apply \"OR\" on the two files\n",
    "import numpy as np\n",
    "import nrrd\n",
    "\n",
    "nrrd1 = nrrd.read(f\"./nrrd/micro_ct_v2/flipped.nrrd\")[0]\n",
    "nrrd2 = nrrd.read(f\"./nrrd/micro_ct_v3/flipped.nrrd\")[0]\n",
    "\n",
    "nrrd_array = 1 - (1 - nrrd1[0]) * (1 - nrrd2 // 255)\n",
    "nrrd.write(f\"./nrrd/v2_or_v3.nrrd\", nrrd_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nrrd1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m nrrd_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogical_or(\u001b[43mnrrd1\u001b[49m[\u001b[38;5;241m0\u001b[39m], nrrd2 \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m      2\u001b[0m nrrd\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./nrrd/v2_or_v3.nrrd\u001b[39m\u001b[38;5;124m\"\u001b[39m, nrrd_array)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nrrd1' is not defined"
     ]
    }
   ],
   "source": [
    "nrrd_array = np.logical_or(nrrd1[0], nrrd2 / 255)\n",
    "nrrd.write(f\"./nrrd/v2_or_v3.nrrd\", nrrd_array)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
